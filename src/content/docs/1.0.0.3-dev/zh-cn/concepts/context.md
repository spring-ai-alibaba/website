---
title: "上下文 (Context)"
description: "理解上下文 (Context) 的概念，以及如何在 SAA 中运用上下文工程 (Context Engineering) 来构建高效的智能体。"
---

## 核心理念：LLM 是 CPU，上下文是 RAM

在构建高级智能体时，我们很快会发现，与大语言模型（LLM）的交互远不止是发送一个简单的“提示词 (Prompt)”。更准确的视角是，我们在为 LLM 这个强大的“中央处理器 (CPU)”管理其有限的“工作内存 (RAM)”，这个“工作内存”就是**上下文 (Context)**。

-   **上下文窗口 (Context Window)** 就是模型的 RAM，它的大小是有限的。
-   所有需要模型处理的信息——指令、用户问题、历史对话、外部知识、工具结果——都必须被加载到这个窗口中。
-   与 RAM 类似，上下文窗口的容量越大，成本（Token 消耗和费用）和延迟就越高。

因此，**上下文工程 (Context Engineering)** —— 这门在 Agent 执行的每一步中，都精确地向上下文窗口填充正确信息的艺术和科学——是构建高效、健壮 Agent 的首要工作。

## 上下文的构成要素

一个典型的上下文主要由以下三类信息构成：

1.  **指令 (Instructions)**
    *   **职责**：告诉模型“做什么”和“如何做”。这是我们通常理解的**提示词 (Prompt)**，但它只是上下文的一部分。
    *   **示例**：系统指令 (`System Prompt`)、用户的具体问题 (`User Message`)、角色扮演要求、输出格式规范、少样本示例 (`Few-shot Examples`)。

    > **什么是提示词 (Prompt)？**
    >
    > 对于熟悉 ChatGPT 的用户来说，提示词可能只是对话框中输入的文本。但在技术实现上，一个提示词远不止于此。它是一种**结构化的、基于语言的输入**，用于引导 AI 模型产生特定的输出。
    >
    > 与其说它是一个简单的字符串，不如说它是一个由多条**消息 (Message)** 构成的集合，每条消息都拥有自己的**角色 (Role)**：
    > -   **系统角色 (System Role)**: 设定 AI 模型的行为准则、个性或总体目标，为整个交互提供宏观背景。例如，“你是一个专业的 Java 技术顾问。”
    > -   **用户角色 (User Role)**: 代表最终用户的输入、问题或指令。
    > -   **助手角色 (Assistant Role)**: 代表 AI 模型之前的回复。将历史回复作为上下文的一部分，对于维持多轮对话的连贯性至关重要。
    >
    > 正是由于这种复杂的结构和与模型交互的微妙性，“提示词工程 (Prompt Engineering)”已经发展成为一门专门的学科，旨在研究如何通过精心设计提示词来最大化地提升模型输出的质量。

2.  **知识 (Knowledge)**
    *   **职责**：为模型提供完成任务所需的**外部信息**，弥补其内部知识的不足或过时。
    *   **示例**：通过 RAG 从向量数据库中检索出的相关文档片段、从关系型数据库中查询出的业务数据。

3.  **工具反馈 (Tool Feedback)**
    *   **职责**：Agent 调用外部工具（如 API、代码解释器）后返回的执行结果。这是 Agent 感知外部世界、进行下一步规划和决策的关键数据。
    *   **示例**：调用天气查询 API 后返回的 JSON 结果、执行数据库查询后返回的表格数据。

## SAA 中的上下文工程策略

SAA 的核心架构，特别是 `StateGraph`，为实践先进的上下文工程策略提供了强大的原生支持。

### 写 / 选上下文 (Write / Select)

这是最基础也是最重要的策略。SAA 通过 `StateGraph` 的状态对象完美地实现了这一模式。

-   **`StateGraph` 的 State 对象 = 暂存区 (Scratchpad)**：你可以将 `StateGraph` 的状态对象理解为一个位于上下文窗口之外的、持久化的“暂存区”。它记录了 Agent 工作流中所有需要跨步骤传递的数据。

-   **写 (Write)**：在图的任何一个节点执行完毕后（例如，`LlmNode` 生成了思考过程，或 `ToolNode` 返回了 API 结果），都可以将这些信息**写入**到 `State` 对象中。这避免了将所有中间过程都堆积在上下文窗口里。

-   **选 (Select)**：当流程进入下一个需要与 LLM 交互的 `LlmNode` 时，我们可以**精确地选择** `State` 对象中的哪些信息（例如，只选择最新的工具结果和原始用户问题，忽略之前的思考过程），将它们组合成新的**指令 (Prompt)**，然后才送入模型的上下文窗口。

> **SAA 优势**：通过 `StateGraph` 对状态的显式管理，SAA 让开发者对上下文的“写”和“选”拥有了像素级的精细控制能力，这是实现复杂 Agent 的基础。

### 压缩上下文 (Compress)

当对话历史或工具反馈过长时，我们需要对其进行压缩，以节省 Token。

-   **SAA 实现**：SAA 的可组合性让实现压缩逻辑变得简单。开发者可以：
    -   **创建摘要节点**：在图中插入一个自定义的 `SummaryNode`。该节点的逻辑是：读取 `State` 中的多轮对话历史，调用 LLM 对其进行总结，然后用生成的摘要替换掉 `State` 中的原始历史。
    -   **后处理工具结果**：在自定义的 `ToolNode` 逻辑中，对返回的冗长的 API 结果进行解析和剪裁，只提取关键信息写入 `State`。

### 隔离上下文 (Isolate)

对于极其复杂的任务，将所有逻辑都放在一个巨大的上下文中会导致模型性能下降。此时，需要将上下文进行隔离。

-   **SAA 实现**：这直接对应 SAA 的**多智能体**和**子图**能力。
    -   **多智能体**：使用 `FlowAgent`（如 `LlmRoutingAgent` 作为主管）将一个复杂任务分解给多个专业的子智能体。每个子智能体都拥有自己独立的 `StateGraph` 和上下文，只专注于处理自己的子任务。这极大地降低了单个上下文窗口的负担，提升了整体性能。
    -   **子图 (Sub-Graph)**：一个 `StateGraph` 可以将另一个完整的 `StateGraph` 作为 `SubGraphNode` 来调用，执行一个封装好的子流程。这同样实现了逻辑单元和上下文的隔离，提升了模块化和复用性。

## 进一步阅读

我们推荐您阅读上下文工程的原文以了解更多理论背景：

-   **[Context Engineering for Agents](https://blog.langchain.com/context-engineering-for-agents/)**
